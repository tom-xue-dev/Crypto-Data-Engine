import os
import requests
import hashlib
import concurrent.futures
import multiprocessing
import zipfile
import pandas as pd
from datetime import datetime
from dateutil.relativedelta import relativedelta
from tqdm import tqdm
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from .exchange_factory import ExchangeFactory


class DownloadContext:
    """ä¸‹è½½ä¸Šä¸‹æ–‡ï¼ˆé‡å‘½åï¼Œä¸“æ³¨äºä¸‹è½½ï¼‰"""

    def __init__(self, config: Dict):
        self.save_dir = config['data_dir']
        self.completed_downloads_file = config.get('completed_downloads_file',
                                                   Path(config['data_dir']) / "completed_downloads.txt")
        self.exchange_name = config['exchange_name']

        # æ•°æ®å¤„ç†ç›¸å…³é…ç½®
        self.output_format = config.get('output_format', 'parquet')
        self.compression = config.get('compression', 'brotli')
        self.sort_by_timestamp = config.get('sort_by_timestamp', True)
        self.remove_duplicates = config.get('remove_duplicates', True)

        # åˆ›å»ºäº¤æ˜“æ‰€é€‚é…å™¨
        self.exchange_adapter = ExchangeFactory.create_adapter(
            self.exchange_name, config
        )


class FileDownloader:
    """ä¸“æ³¨äºæ–‡ä»¶ä¸‹è½½çš„ä¸‹è½½å™¨"""

    def __init__(self, context: DownloadContext):
        self.context = context
        self.adapter = context.exchange_adapter

    @staticmethod
    def verify_checksum(file_path: str, expected_checksum: str) -> bool:
        """éªŒè¯æ–‡ä»¶æ ¡éªŒå’Œ"""
        expected_checksum = expected_checksum.split()[0].strip()
        sha256 = hashlib.sha256()

        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256.update(chunk)

        computed_checksum = sha256.hexdigest()
        return computed_checksum == expected_checksum

    def download_file(self, symbol: str, year: int, month: int) -> Optional[str]:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶ï¼Œè¿”å›ä¸‹è½½åçš„æ–‡ä»¶è·¯å¾„"""
        file_name = self.adapter.get_file_name(symbol, year, month)
        url = self.adapter.build_download_url(symbol, year, month)

        # åˆ›å»ºäº¤æ˜“æ‰€ç‰¹å®šçš„ä¿å­˜ç›®å½•
        exchange_dir = os.path.join(self.context.save_dir, self.adapter.name)
        os.makedirs(exchange_dir, exist_ok=True)

        local_file_path = os.path.join(exchange_dir, file_name)

        # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½è¿‡
        if os.path.exists(local_file_path):
            return None  # å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½

        try:
            # æ£€æŸ¥è¿œç¨‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            response = requests.head(url, timeout=5)
            if response.status_code != 200:
                return None

            # ä¸‹è½½æ–‡ä»¶
            r = requests.get(url, stream=True, timeout=30)
            r.raise_for_status()

            with open(local_file_path, "wb") as f:
                for chunk in r.iter_content(chunk_size=8192):
                    if chunk:  # è¿‡æ»¤ç©ºå—
                        f.write(chunk)

            # éªŒè¯æ ¡éªŒå’Œï¼ˆå¦‚æœæ”¯æŒï¼‰
            if self._verify_download(symbol, year, month, local_file_path):
                return local_file_path
            else:
                # æ ¡éªŒå’ŒéªŒè¯å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶
                os.remove(local_file_path)
                return None

        except Exception as e:
            print(f"Download failed for {symbol} {year}-{month:02d}: {e}")
            # æ¸…ç†å¯èƒ½çš„ä¸å®Œæ•´æ–‡ä»¶
            if os.path.exists(local_file_path):
                os.remove(local_file_path)
            return None

    def _verify_download(self, symbol: str, year: int, month: int, file_path: str) -> bool:
        """éªŒè¯ä¸‹è½½çš„æ–‡ä»¶ï¼ˆæ ¡éªŒå’Œç­‰ï¼‰"""
        try:
            # å¦‚æœäº¤æ˜“æ‰€æ”¯æŒæ ¡éªŒå’ŒéªŒè¯
            if hasattr(self.adapter, 'supports_checksum') and self.adapter.supports_checksum:
                checksum_url = self.adapter.build_checksum_url(symbol, year, month)
                if checksum_url:
                    checksum_response = requests.get(checksum_url, timeout=10)
                    if checksum_response.status_code == 200:
                        expected_checksum = checksum_response.text
                        if not self.verify_checksum(file_path, expected_checksum):
                            print(f"Checksum verification failed for {symbol} {year}-{month:02d}")
                            return False

            # åŸºæœ¬çš„æ–‡ä»¶å¤§å°æ£€æŸ¥
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                print(f"Downloaded file is empty: {symbol} {year}-{month:02d}")
                return False

            return True

        except Exception as e:
            print(f"Download verification failed for {symbol} {year}-{month:02d}: {e}")
            return False

    def _convert_to_parquet(self, zip_path: str) -> Optional[str]:
        """å°†ä¸‹è½½çš„ zip æ–‡ä»¶è§£å‹å¹¶è½¬æ¢ä¸º parquet"""
        if self.context.output_format != 'parquet':
            return None

        if not os.path.exists(zip_path):
            return None

        try:
            # è§£æç¬¦å·å¹¶å‡†å¤‡è¾“å‡ºç›®å½•
            exchange_dir = os.path.join(self.context.save_dir, self.adapter.name)
            base_name = os.path.basename(zip_path)
            symbol = base_name.split('-')[0].split('_')[0]
            symbol_dir = os.path.join(exchange_dir, symbol)
            os.makedirs(symbol_dir, exist_ok=True)

            with zipfile.ZipFile(zip_path, 'r') as zf:
                csv_files = [f for f in zf.namelist() if f.endswith('.csv')]
                if not csv_files:
                    return None
                csv_name = csv_files[0]
                parquet_name = os.path.splitext(os.path.basename(csv_name))[0] + '.parquet'
                parquet_path = os.path.join(symbol_dir, parquet_name)

                # å¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡
                if os.path.exists(parquet_path):
                    return parquet_path

                with zf.open(csv_name) as f:
                    df = pd.read_csv(f)

            if self.context.remove_duplicates:
                df = df.drop_duplicates()

            if self.context.sort_by_timestamp:
                time_cols = [c for c in df.columns if 'time' in c.lower()]
                if time_cols:
                    df = df.sort_values(time_cols[0])

            df.to_parquet(parquet_path, compression=self.context.compression, index=False)
            return parquet_path
        except Exception as e:
            print(f"Failed to convert {zip_path} to parquet: {e}")
            return None

    def run_download_pipeline(self, config: Dict):
        """è¿è¡Œä¸‹è½½æµæ°´çº¿ - åªè´Ÿè´£ä¸‹è½½"""
        max_threads = config['max_threads']
        queue_size = config.get('queue_size', 100)
        start_date = config['start_date']
        end_date = config['end_date']
        os.makedirs(self.context.save_dir, exist_ok=True)

        download_counter = multiprocessing.Value('i', 0)
        failed_counter = multiprocessing.Value('i', 0)

        # è·å–äº¤æ˜“å¯¹åˆ—è¡¨
        if config['symbols'] == "auto":
            symbols = self.adapter.get_all_symbols(config.get('filter_suffix'))
        else:
            symbols = config['symbols']

        # è¯»å–å·²å®Œæˆä¸‹è½½
        completed_downloads = self._read_completed_file(self.context.completed_downloads_file)
        download_tasks = self._generate_download_tasks(symbols, start_date, end_date, completed_downloads)

        total_tasks = len(download_tasks)
        print(f"ğŸ“Š Exchange: {self.adapter.name}")
        print(f"ğŸ“¥ Total download tasks: {total_tasks}")

        if total_tasks == 0:
            print("âœ… No new files to download")
            return

        start_time = time.time()

        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘ä¸‹è½½
        with tqdm(total=total_tasks, desc=f"[{self.adapter.name} Download]") as pbar:
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:
                future_to_task = {
                    executor.submit(self._download_task, symbol, year, month, pbar, download_counter, failed_counter):
                        (symbol, year, month)
                    for (symbol, year, month) in download_tasks
                }

                for future in concurrent.futures.as_completed(future_to_task):
                    symbol, year, month = future_to_task[future]
                    try:
                        success = future.result()
                        if success:
                            task_id = f"{self.context.exchange_name}/{symbol}/{year}-{month}"
                            self._append_completed_file(self.context.completed_downloads_file, task_id)
                    except Exception as e:
                        print(f"Task failed for {symbol} {year}-{month}: {e}")

        end_time = time.time()

        print(f"\nâœ… {self.adapter.name} ä¸‹è½½å®Œæˆ:")
        print(f"   ğŸ“¥ æˆåŠŸä¸‹è½½: {download_counter.value}")
        print(f"   âŒ å¤±è´¥/è·³è¿‡: {failed_counter.value}")
        print(f"   â° è€—æ—¶: {end_time - start_time:.2f} ç§’")

    def _download_task(self, symbol: str, year: int, month: int, pbar, success_counter, failed_counter) -> bool:
        """å•ä¸ªä¸‹è½½ä»»åŠ¡"""
        try:
            result = self.download_file(symbol, year, month)
            pbar.update(1)

            # æ— è®ºæ˜¯å¦æ–°ä¸‹è½½ï¼Œå°è¯•è½¬æ¢ä¸º parquet
            local_path = result
            if not local_path:
                exchange_dir = os.path.join(self.context.save_dir, self.adapter.name)
                local_path = os.path.join(exchange_dir, self.adapter.get_file_name(symbol, year, month))
            if local_path:
                self._convert_to_parquet(local_path)

            if result:
                with success_counter.get_lock():
                    success_counter.value += 1
                return True
            else:
                with failed_counter.get_lock():
                    failed_counter.value += 1
                return False

        except Exception as e:
            print(f"Download task error for {symbol} {year}-{month}: {e}")
            pbar.update(1)
            with failed_counter.get_lock():
                failed_counter.value += 1
            return False

    def _read_completed_file(self, path: str) -> set:
        """è¯»å–å·²å®Œæˆä¸‹è½½æ–‡ä»¶"""
        if not os.path.exists(path):
            return set()
        with open(path, "r") as f:
            return set(line.strip() for line in f.readlines())

    def _append_completed_file(self, path: str, task: str):
        """è¿½åŠ å®Œæˆçš„ä¸‹è½½ä»»åŠ¡åˆ°æ–‡ä»¶"""
        with open(path, "a") as f:
            f.write(task + "\n")

    def _generate_download_tasks(self, symbols: List[str], start_date: str, end_date: str,
                                 completed: set) -> List[Tuple[str, int, int]]:
        """ç”Ÿæˆä¸‹è½½ä»»åŠ¡åˆ—è¡¨"""
        tasks = []

        for symbol in symbols:
            current_date = datetime.strptime(start_date, "%Y-%m")
            end_dt = datetime.strptime(end_date, "%Y-%m")

            while current_date <= end_dt:
                task_id = f"{self.context.exchange_name}/{symbol}/{current_date.year}-{current_date.month}"
                if task_id not in completed:
                    tasks.append((symbol, current_date.year, current_date.month))
                current_date += relativedelta(months=1)

        return tasks

    def get_downloaded_files(self, symbol: str = None) -> List[str]:
        """è·å–å·²ä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨"""
        exchange_dir = os.path.join(self.context.save_dir, self.adapter.name)
        if not os.path.exists(exchange_dir):
            return []

        files = []
        for file in os.listdir(exchange_dir):
            if file.endswith('.zip'):  # å‡è®¾ä¸‹è½½çš„æ˜¯zipæ–‡ä»¶
                if symbol is None or symbol.upper() in file.upper():
                    files.append(os.path.join(exchange_dir, file))

        return sorted(files)


# ä¿æŒå‘åå…¼å®¹æ€§çš„åˆ«å
MultiExchangeDownloadContext = DownloadContext
MultiExchangeDownloader = FileDownloader
