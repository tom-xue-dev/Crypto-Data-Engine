-# Quantitative Backtesting System
-
-> ğŸš€ A Modular, Distributed Framework for Quantitative Trading Backtesting
-
-This project implements a scalable quantitative backtesting system for cryptocurrency trading strategies. It processes high-frequency tick data from sources like Binance, aggregates it into bars (e.g., tick bars, volume bars, dollar bars), generates features, produces trading signals, performs backtesting, and visualizes results.
-
-The system is built with a microservices architecture and supports distributed computing via Celery and Ray. Each module communicates via HTTP APIs to ensure loose coupling, scalability, and independent deployment.
-
----
-
-## ğŸ”§ Key Modules
-
-- **Tick Data Download**: Fetches and processes raw trade data from exchanges like Binance.
-- **Bar Aggregation**: Constructs custom bars (tick, volume, dollar) from raw data.
-- **Feature Generation**: Computes statistical features and technical indicators.
-- **Signal Generation**: Applies rules or ML models to produce trading signals.
-- **Backtesting**: Simulates trading strategies with slippage, fees, and risk controls.
-- **Visualization**: Creates charts, reports, and dashboards for strategy evaluation.
-
----
-
-## ğŸ“‚ Project Structure
-
-```text
-project/
-â”œâ”€â”€ api_gateway/                  # FastAPI API Gateway for HTTP endpoints
-â”‚   â”œâ”€â”€ main.py                   # FastAPI app entrypoint
-â”‚   â””â”€â”€ tasks.py                  # Celery task definitions
-â”œâ”€â”€ celery_worker/                # Celery workers for task execution
-â”‚   â””â”€â”€ worker.py                 # Worker configuration and tasks
-â”œâ”€â”€ ray_cluster/                  # Ray integration for distributed compute
-â”‚   â””â”€â”€ ray_tasks.py              # Ray remote functions
-â”œâ”€â”€ modules/                      # Microservices for each core function
-â”‚   â”œâ”€â”€ download/                 # Tick data download service
-â”‚   â”œâ”€â”€ bar_aggregation/          # Bar construction service
-â”‚   â”œâ”€â”€ feature_generation/       # Feature engineering service
-â”‚   â”œâ”€â”€ signal_generation/        # Signal creation service
-â”‚   â”œâ”€â”€ backtesting/              # Backtesting engine service
-â”‚   â””â”€â”€ visualization/            # Reporting and visualization service
-â”œâ”€â”€ configs/                      # Configuration files (YAML/.env)
-â”‚   â”œâ”€â”€ celery_config.py          # Celery settings
-â”‚   â””â”€â”€ ray_config.py             # Ray cluster settings
-â”œâ”€â”€ data/                         # Raw and processed data storage
-â”œâ”€â”€ docker-compose.yml            # Containerized deployment
-â”œâ”€â”€ requirements.txt              # Python dependencies
-â””â”€â”€ README.md                     # This file
-```
-
----
+# Distributed Cryptocurrency Backtesting System
 
-## âš™ï¸ Architecture Overview
-
-```
-Client â†’ FastAPI (API Gateway)
-         â†’ Celery.delay() Submit Task
-         â†’ Redis (Broker/Backend)
-         â†’ Celery Worker
-         â†’ download_task() â†’ Ray.remote()
-         â†’ Ray Cluster (distributed compute)
-         â†’ Optional Redis Backend (for results)
-```
+A modular framework for collecting market data, engineering features and running strategy backtests. The project targets high-frequency cryptocurrency trading and combines a FastAPI web server with Celery workers so heavy workloads can be processed in parallel.
 
-### Description
+## Features
 
-- **FastAPI Gateway**: Receives and routes incoming requests.
-- **Celery Dispatcher**: Enqueues tasks to Redis and distributes to workers.
-- **Ray Cluster**: Handles compute-intensive IO/CPU tasks in parallel.
-- **Redis**: Acts as broker/backend for Celery task coordination.
+- **Tick data scraper** â€“ download and verify raw trade data from exchanges.
+- **Bar and feature pipeline** â€“ aggregate ticks into research datasets and compute indicators.
+- **Backtesting engine** â€“ evaluate strategies with realistic fees and slippage.
+- **Distributed tasks** â€“ Celery workers execute jobs concurrently; optional Ray integration for large scale compute.
+- **CLI utilities** â€“ Typer based commands to start servers, workers and manage configuration.
 
----
+## Project layout
 
-## ğŸ›  Installation & Setup
+```
+BTC-trading/
+â”œâ”€â”€ deploy/                      # Docker compose and deployment helpers
+â”œâ”€â”€ docs/                        # Additional documentation (e.g. API_README.md)
+â”œâ”€â”€ src/
+â”‚   â”œâ”€â”€ crypto_data_engine/      # FastAPI server and data services
+â”‚   â””â”€â”€ task_manager/            # Celery configuration and workers
+â”œâ”€â”€ tests/                       # Pytest suite
+â”œâ”€â”€ pyproject.toml               # Project metadata & dependencies (Poetry)
+â””â”€â”€ README.md
+```
 
-### Prerequisites
+## Getting started
 
-- Python 3.10+
-- Redis (broker/backend)
-- Ray (`pip install ray[default]`)
-- Docker (optional, for full deployment)
+### Installation
 
-### Setup
+This project uses [Poetry](https://python-poetry.org/) for dependency management:
 
 ```bash
-git clone https://github.com/your-repo/quant-backtest-system.git
-cd quant-backtest-system
-pip install -r requirements.txt
+poetry install
 ```
 
-### Start Services
+### Launch the API server
 
 ```bash
-# Redis
-redis-server         # or: docker run -d -p 6379:6379 redis
-
-# Ray (start head node)
-ray start --head
-
-# Celery worker
-celery -A api_gateway.tasks worker --loglevel=info
-
-# API Gateway
-uvicorn api_gateway.main:app --reload
+poetry run main start
 ```
 
-### Docker (optional)
+### Run a Celery worker
 
 ```bash
-docker-compose up -d
+poetry run main run-worker downloader
 ```
 
----
-
-## ğŸš€ Usage Example: Submitting a Download Task
+### Run the test suite
 
 ```bash
-curl -X POST "http://localhost:8000/submit_download"      -H "Content-Type: application/json"      -d '{
-           "symbols": ["BTCUSDT", "ETHUSDT"],
-           "start_date": "2022-01",
-           "end_date": "2022-03"
-         }'
+pytest
 ```
 
-You will receive a `task_id`.
+## Docker deployment
 
-Check status:
+A minimal `docker-compose.yml` is provided under `deploy/`:
 
 ```bash
-curl http://localhost:8000/status/{task_id}
+docker compose -f deploy/docker-compose.yml up -d
 ```
 
----
-
-## ğŸ” Monitoring
-
-| Component | Tool                  | URL                         |
-|-----------|-----------------------|-----------------------------|
-| Celery    | Flower                | http://localhost:5555       |
-| Ray       | Ray Dashboard         | http://localhost:8265       |
-
----
-
-## â• Extending the System
-
-To add a new module (e.g., feature generation):
-
-1. Create a FastAPI service under `modules/feature_generation/`
-2. Add Celery tasks that call Ray remote functions
-3. Define a `POST` endpoint in API Gateway to submit this task
-4. Optionally, register this module in your gateway or orchestrator
-
----
-
-## ğŸ“ˆ Performance & Scaling
-
-- **Horizontal Scaling**: Add more Celery workers or Ray nodes
-- **Parquet Format**: Efficient for storing high-frequency data
-- **Fault Tolerance**:
-  - Celery retries failed tasks
-  - Ray recovers failed workers automatically
-
----
-
-## ğŸ”® Future Enhancements
-
-- Add ML-based signal generation (e.g., PyTorch integration)
-- Use Kubernetes for full orchestration
-- Support additional exchanges (e.g., Coinbase, Kraken)
-
----
-
-## ğŸ“§ Contact
-
-For issues, please open a GitHub issue or contact:  
-ğŸ“® `your-email@example.com`
-
----
-
-## ğŸŒŸ Contributing
-
-Pull requests are welcome! Please focus on:
+## Contributing
 
-- Modular, testable design
-- Documentation and clarity
-- Code quality and extensibility
+Pull requests are welcome. Please add tests for new features and keep documentation up to date.
